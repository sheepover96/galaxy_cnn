{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Users/sheep/.pyenv/versions/3.6.1/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data read start\n",
      "finished\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import csv\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "import itertools\n",
    "from astropy.io import fits\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "CLASS_NUM = 2 # the number of classes for classification\n",
    "\n",
    "#img_channels = 1\n",
    "img_channels = 4\n",
    "IMG_CHANNEL = 4\n",
    "IMG_SIZE = 50\n",
    "\n",
    "#input_shape = (1, 239, 239) # ( channels, cols, rows )\n",
    "raw_size = (239, 239, img_channels)\n",
    "#raw_size = (48, 48, img_channels)\n",
    "input_shape = (50, 50, IMG_CHANNEL)\n",
    "#input_shape = (24, 24, img_channels)\n",
    "\n",
    "train_test_split_rate = 0.8\n",
    "#train_test_split_rate = 1\n",
    "nb_epoch = 20\n",
    "batch_size = 10\n",
    "validation_split = 0.1\n",
    "#validation_split = 0.0\n",
    "\n",
    "\n",
    "BATCH_SIZE = 10\n",
    "NEPOCH = 100\n",
    "KFOLD = 5\n",
    "\n",
    "IMG_IDX = 2\n",
    "LABEL_IDX = 2 +  IMG_CHANNEL\n",
    "PNG_LABEL_IDX = 2 + IMG_CHANNEL\n",
    "\n",
    "FILE_HOME = \"/Users/sheep/Documents/research/project/hsc\"\n",
    "\n",
    "DATA_ROOT_DIR = '/Users/sheep/Documents/research/project/hsc'\n",
    "ROOT_DIR = os.path.dirname(os.path.abspath(sys.argv[0]))\n",
    "\n",
    "PNG_IMG_DIR = '/Users/sheep/Documents/research/project/hsc/png_images'\n",
    "PNG_IMG_DIR = '/Users/sheep/documents/research/project/hsc/png_images'\n",
    "\n",
    "SAVE_DIR = '/Users/sheep/Documents/research/project/hsc/saved_data'\n",
    "DATASET = 'dataset/dropout_test.csv'\n",
    "\n",
    "\n",
    "class DatasetLoader:\n",
    "\n",
    "    def __init__(self, csv_file_path, root_dir, start=1, end=12266):\n",
    "        data_frame = pd.read_csv(csv_file_path, header=None)\n",
    "        self.root_dir = root_dir\n",
    "        self.dataset_frame_list = []\n",
    "        self.dataset = []\n",
    "        for i in range(CLASS_NUM):\n",
    "            if i == 1:\n",
    "                tmp_dataframe = data_frame[data_frame[LABEL_IDX]==i]\n",
    "                self.dataset_frame_list.append(tmp_dataframe[start:end])\n",
    "            else:\n",
    "                self.dataset_frame_list.append(data_frame[data_frame[LABEL_IDX]==i])\n",
    "            self.dataset.append( self.create_dataset(i) )\n",
    "\n",
    "    def create_dataset(self, label):\n",
    "        data_frame = self.get_dataframe(label)\n",
    "        data_list = []\n",
    "\n",
    "        for idx, row_data in data_frame.iterrows():\n",
    "            img_no = str(row_data[0])\n",
    "\n",
    "            png_img_name = row_data[1]\n",
    "\n",
    "            img_names = row_data[2:IMG_IDX+IMG_CHANNEL]\n",
    "            img_names = [ path for path in img_names ]\n",
    "\n",
    "            label = row_data[LABEL_IDX]\n",
    "            #label = np_utils.to_categorical(label, num_classes=CLASS_NUM)\n",
    "\n",
    "            image = self.load_image(img_names)\n",
    "            image = self.crop_center(image, IMG_SIZE, IMG_SIZE)\n",
    "            #image = self.normalize2(image)\n",
    "            #image_feature = self.extract_feature(( normalized_image + 0.5 )*10)\n",
    "            #print(image_feature, label)\n",
    "\n",
    "            data_list.append( (label, image, img_no, png_img_name, img_names) )\n",
    "\n",
    "        return data_list\n",
    "    \n",
    "    \n",
    "    def normalize1(self, image):\n",
    "        flat_image = image.flatten()\n",
    "        mean = flat_image.mean()\n",
    "        std = flat_image.std()\n",
    "        image = np.where(image < mean - 1*std, mean - 1*std, image)\n",
    "        image = np.where(image > mean + 1*std, mean + 1*std, image)\n",
    "        image = (image + 1*std - mean)\n",
    "        \n",
    "        return image\n",
    "    \n",
    "    def normalize2(self, image):\n",
    "        image = image + 1.0\n",
    "        image = np.where(image < 0, 0, image)\n",
    "        image = np.where(image  > 5, 5, image)\n",
    "        return image\n",
    "\n",
    "        \n",
    "    def crop_center(self, img,cropx, cropy):\n",
    "        y,x,z = img.shape\n",
    "        startx = x//2-(cropx//2)\n",
    "        starty = y//2-(cropy//2)\n",
    "        return img[starty:starty+cropy,startx:startx+cropx,:]\n",
    "\n",
    "    def get_dataframe(self, label):\n",
    "        return self.dataset_frame_list[label]\n",
    "\n",
    "    def get_dataset(self, label):\n",
    "        return self.dataset[label]\n",
    "\n",
    "    def zoom_img(self, img, original_size, pickup_size):\n",
    "        startpos = int(original_size / 2) - int(pickup_size / 2)\n",
    "        img = img[startpos:startpos+pickup_size, startpos:startpos+pickup_size]\n",
    "        return img\n",
    "\n",
    "    def load_image(self, img_paths):\n",
    "        image_path_list = [self.root_dir + img_path for img_path in img_paths]\n",
    "        image_list = []\n",
    "        for filepath in image_path_list:\n",
    "            row_data = fits.getdata(filepath)\n",
    "            image_list.append(row_data)\n",
    "        image = np.array([img for img in image_list]).transpose(1,2,0)\n",
    "        return image\n",
    "\n",
    "\n",
    "\n",
    "#create dataset for cross validation\n",
    "print('data read start')\n",
    "\n",
    "dataset_no_normalize = DatasetLoader(DATASET, DATA_ROOT_DIR, 1, 5000)\n",
    "other_dataset_no_normalize = DatasetLoader(DATASET, DATA_ROOT_DIR, start=5001)\n",
    "\n",
    "print('finished')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalize start\n",
      "normalize finished\n"
     ]
    }
   ],
   "source": [
    "def normalize1(image):\n",
    "    flat_image = image.flatten()\n",
    "    mean = flat_image.mean()\n",
    "    std = flat_image.std()\n",
    "    image = np.where(image < mean - 2*std, mean - 2*std, image)\n",
    "    image = np.where(image > mean + 2*std, mean + 2*std, image)\n",
    "    image = (image + 2*std - mean)\n",
    "\n",
    "    return image\n",
    "\n",
    "def normalize2(image):\n",
    "    image = image + 1.0\n",
    "    image = np.where(image < 0, 0, image)\n",
    "    image = np.where(image  > 5, 5, image)\n",
    "    return image\n",
    "\n",
    "def normalize_all_data(dataset_obj):\n",
    "    for data_list in dataset_obj.dataset:\n",
    "        for idx in range(len(data_list)):\n",
    "            (label, image, img_no, png_img_name, img_names) = data_list[idx]\n",
    "            data_list[idx] =  (label, normalize1(image), img_no, png_img_name, img_names)\n",
    "\n",
    "def normalize_all_data2(dataset_obj):\n",
    "    for idx in range(len(dataset_obj)):\n",
    "        (label, image, img_no, png_img_name, img_names) = dataset_obj[idx]\n",
    "        dataset_obj[idx] =  (label, DatasetLoader.normalize2(None, image), img_no, png_img_name, img_names)\n",
    "            \n",
    "print('normalize start')\n",
    "dataset = dataset_no_normalize\n",
    "other_dataset = other_dataset_no_normalize\n",
    "normalize_all_data(dataset)\n",
    "true_dataset = dataset.get_dataset(1)\n",
    "false_dataset = dataset.get_dataset(0)\n",
    "\n",
    "normalize_all_data(other_dataset)\n",
    "other_true_dataset = other_dataset.get_dataset(1)\n",
    "other_true_test_img = list(map(lambda data: data[1], other_true_dataset))\n",
    "other_true_test_label = list(map(lambda data: data[0], other_true_dataset))\n",
    "other_true_test_catalog_ids_set = list(map(lambda data: data[2], other_true_dataset))\n",
    "other_true_test_png_img_set = list(map(lambda data: data[3], other_true_dataset))\n",
    "other_true_test_paths_set = list(map(lambda data: data[4], other_true_dataset))\n",
    "print('normalize finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sheep/.pyenv/versions/3.6.1/lib/python3.6/site-packages/ipykernel_launcher.py:35: RuntimeWarning: invalid value encountered in float_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true train 3999\n",
      "true test 8265\n",
      "false train 3990\n",
      "false test 53\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float32').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-fccb75b2fba0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;31m#SVM classification\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'gini'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_img_feature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0mpred_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_img_feature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.1/lib/python3.6/site-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    245\u001b[0m         \"\"\"\n\u001b[1;32m    246\u001b[0m         \u001b[0;31m# Validate or convert input data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"csc\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    248\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'csc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0missparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.1/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    405\u001b[0m                              % (array.ndim, estimator_name))\n\u001b[1;32m    406\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m             \u001b[0m_assert_all_finite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m     \u001b[0mshape_repr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_shape_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.1/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X)\u001b[0m\n\u001b[1;32m     56\u001b[0m             and not np.isfinite(X).all()):\n\u001b[1;32m     57\u001b[0m         raise ValueError(\"Input contains NaN, infinity\"\n\u001b[0;32m---> 58\u001b[0;31m                          \" or a value too large for %r.\" % X.dtype)\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float32')."
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import itertools\n",
    "IMG_CHANNEL = 4\n",
    "\n",
    "FEATURE_RANGE = [15]\n",
    "PATTERNS = list(itertools.combinations([i for i in range(IMG_CHANNEL)], 2))\n",
    "\n",
    "def extract_feature(image):\n",
    "    feature_list = []\n",
    "    image = image/255\n",
    "    for size in FEATURE_RANGE:\n",
    "        for (channel1, channel2) in PATTERNS:\n",
    "            image1 = image[:,:,channel1]\n",
    "            image2 = image[:,:,channel2]\n",
    "            feature_list.append(calc_pixel_ratio(image1, image2, size))\n",
    "            feature_list.append(calc_pixel_ratio_exp(image1, image2, size))\n",
    "\n",
    "        for channel in range(IMG_CHANNEL):\n",
    "            cropped_image = image[:,:,channel]\n",
    "            mean, std = calc_pixel_mean(cropped_image, size)\n",
    "            feature_list.append(mean)\n",
    "            feature_list.append(std*std)\n",
    "            \n",
    "    return np.array( feature_list )\n",
    "\n",
    "def calc_pixel_mean(image, size):\n",
    "    cropped_image = crop_center2D(image, size, size)\n",
    "    return cropped_image.mean(), cropped_image.std()\n",
    "\n",
    "def calc_pixel_ratio(image1, image2, size):\n",
    "    cropped_image1 = crop_center2D(image1, size, size)\n",
    "    cropped_image2 = crop_center2D(image2, size, size)\n",
    "\n",
    "    return cropped_image1.sum()/cropped_image2.sum()\n",
    "\n",
    "def calc_pixel_ratio_exp(image1, image2, size):\n",
    "    cropped_image1 = crop_center2D(image1, size, size)\n",
    "    cropped_image2 = crop_center2D(image2, size, size)\n",
    "\n",
    "    return np.exp(cropped_image1).sum()/np.exp(cropped_image2).sum()\n",
    "\n",
    "def crop_center2D(img,cropx, cropy):\n",
    "    y,x = img.shape\n",
    "    startx = x//2-(cropx//2)\n",
    "    starty = y//2-(cropy//2)\n",
    "    return img[starty:starty+cropy,startx:startx+cropx]\n",
    "\n",
    "def write_result(zipped_result, output_path):\n",
    "    with open(output_path, 'w') as f:\n",
    "        writer = csv.writer(f)\n",
    "        for result in zipped_result:\n",
    "            cat_id = result[0]\n",
    "            img_paths = result[2]\n",
    "            combined_img_path = result[1]\n",
    "            label = result[3]\n",
    "            float_formatter = lambda x: \"%.4f\" % x\n",
    "            pred = result[4]\n",
    "            # row should be [cat_id, img1, img2, img3, combined_img, correct_label, [probabilties], answer]\n",
    "            row = [cat_id, img_paths, combined_img_path, label, pred]\n",
    "            writer.writerow(row)\n",
    "\n",
    "print('start')\n",
    "kfold = KFold(n_splits=5)\n",
    "\n",
    "true_dataset_fold = kfold.split(true_dataset)\n",
    "false_dataset_fold = kfold.split(false_dataset)\n",
    "\n",
    "accuracies = []\n",
    "for fold_idx, ( (true_train_idx, true_test_idx), (false_train_idx, false_test_idx) ) in\\\n",
    "        enumerate( zip(true_dataset_fold, false_dataset_fold) ):\n",
    "\n",
    "    print(fold_idx)\n",
    "    true_train_data = [ true_dataset[idx] for idx in true_train_idx]\n",
    "    true_test_data = [ true_dataset[idx] for idx in true_test_idx ]\n",
    "    false_train_data = [ false_dataset[idx] for idx in false_train_idx ]\n",
    "    false_test_data = [ false_dataset[idx] for idx in false_test_idx ]\n",
    "\n",
    "    #data augumentation\n",
    "    datagen = ImageDataGenerator(\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=True)\n",
    "\n",
    "    tmp_false_train_data = false_train_data\n",
    "    false_train_data = []\n",
    "    for idx, data in enumerate( tmp_false_train_data ):\n",
    "        label = data[0]\n",
    "        img = data[1]\n",
    "        img_no = data[2]\n",
    "        img_name = data[3]\n",
    "        img_names = data[4]\n",
    "        expanded_image = np.expand_dims(img, axis=0)\n",
    "        generator = datagen.flow(expanded_image, batch_size=1, save_prefix='img', save_format='png')\n",
    "        for ite in range(19):\n",
    "            batch = generator.next()\n",
    "            false_train_data.append( (label, batch[0], img_no, img_name, img_names) )\n",
    "\n",
    "    true_train_img_feature = list(map(lambda data: extract_feature(data[1]), true_train_data))\n",
    "    true_train_img = list(map(lambda data: data[1], true_train_data))\n",
    "    true_train_label = list(map(lambda data: data[0], true_train_data))\n",
    "    \n",
    "    true_test_img_feature = list(map(lambda data: extract_feature(data[1]), true_test_data)) + [extract_feature(data) for data in other_true_test_img]\n",
    "    true_test_img = list(map(lambda data: data[1], true_test_data)) + other_true_test_img\n",
    "    true_test_label = list(map(lambda data: data[0], true_test_data)) + other_true_test_label\n",
    "    true_test_catalog_ids_set = list(map(lambda data: data[2], true_test_data)) + other_true_test_catalog_ids_set\n",
    "    true_test_png_img_set = list(map(lambda data: data[3], true_test_data)) + other_true_test_png_img_set\n",
    "    true_test_paths_set = list(map(lambda data: data[4], true_test_data)) + other_true_test_paths_set\n",
    "    \n",
    "    false_train_img_feature = list(map(lambda data: extract_feature(data[1]), false_train_data))\n",
    "    false_train_img = list(map(lambda data: data[1], false_train_data))\n",
    "    false_train_label = list(map(lambda data: data[0], false_train_data))\n",
    "    \n",
    "    false_test_img_feature = list(map(lambda data: extract_feature(data[1]), false_test_data))\n",
    "    false_test_img = list(map(lambda data: data[1], false_test_data))\n",
    "    false_test_label = list(map(lambda data: data[0], false_test_data))\n",
    "    false_test_catalog_ids_set = list(map(lambda data: data[2], false_test_data))\n",
    "    false_test_png_img_set = list(map(lambda data: data[3], false_test_data))\n",
    "    false_test_paths_set = list(map(lambda data: data[4], false_test_data))\n",
    "    \n",
    "    train_img_feature = true_train_img_feature + false_train_img_feature\n",
    "    train_label = true_train_label + false_train_label\n",
    "    \n",
    "    test_img_feature = true_test_img_feature + false_test_img_feature\n",
    "    test_label = true_test_label + false_test_label\n",
    "    test_catalog_id_set = true_test_catalog_ids_set + false_test_catalog_ids_set\n",
    "    test_png_img_set = true_test_png_img_set + false_test_png_img_set\n",
    "    test_path_set = true_test_paths_set + false_test_paths_set\n",
    "    \n",
    "    print('true train', len(true_train_img))\n",
    "    print('true test', len(true_test_img))\n",
    "    print('false train', len(false_train_img))\n",
    "    print('false test', len(false_test_img))\n",
    "\n",
    "    #SVM classification\n",
    "    model = RandomForestClassifier(criterion='gini', n_estimators=100, random_state=10)\n",
    "    model.fit(train_img_feature, train_label)\n",
    "\n",
    "    pred_result = model.predict(test_img_feature)\n",
    "    write_result(zip(test_catalog_id_set, test_png_img_set, test_path_set, test_label, pred_result), 'res{}.csv'.format(fold_idx))\n",
    "    \n",
    "    print(metrics.accuracy_score(test_label, pred_result))\n",
    "    print(metrics.confusion_matrix(test_label, pred_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
