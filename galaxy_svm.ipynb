{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data read start\n",
      "finished\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import csv\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "import itertools\n",
    "from astropy.io import fits\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "CLASS_NUM = 2 # the number of classes for classification\n",
    "\n",
    "#img_channels = 1\n",
    "img_channels = 4\n",
    "IMG_CHANNEL = 4\n",
    "IMG_SIZE = 50\n",
    "\n",
    "#input_shape = (1, 239, 239) # ( channels, cols, rows )\n",
    "raw_size = (239, 239, img_channels)\n",
    "#raw_size = (48, 48, img_channels)\n",
    "input_shape = (50, 50, IMG_CHANNEL)\n",
    "#input_shape = (24, 24, img_channels)\n",
    "\n",
    "train_test_split_rate = 0.8\n",
    "#train_test_split_rate = 1\n",
    "nb_epoch = 20\n",
    "batch_size = 10\n",
    "validation_split = 0.1\n",
    "#validation_split = 0.0\n",
    "\n",
    "\n",
    "BATCH_SIZE = 10\n",
    "NEPOCH = 100\n",
    "KFOLD = 5\n",
    "\n",
    "IMG_IDX = 2\n",
    "LABEL_IDX = 2 +  IMG_CHANNEL\n",
    "PNG_LABEL_IDX = 2 + IMG_CHANNEL\n",
    "\n",
    "FILE_HOME = \"/Users/sheep/Documents/research/project/hsc\"\n",
    "\n",
    "DATA_ROOT_DIR = '/Users/sheep/Documents/research/project/hsc'\n",
    "ROOT_DIR = os.path.dirname(os.path.abspath(sys.argv[0]))\n",
    "\n",
    "PNG_IMG_DIR = '/Users/sheep/Documents/research/project/hsc/png_images'\n",
    "PNG_IMG_DIR = '/Users/sheep/documents/research/project/hsc/png_images'\n",
    "\n",
    "SAVE_DIR = '/Users/sheep/Documents/research/project/hsc/saved_data'\n",
    "DATASET = 'dataset/dropout_test.csv'\n",
    "\n",
    "\n",
    "class DatasetLoader:\n",
    "\n",
    "    def __init__(self, csv_file_path, root_dir):\n",
    "        data_frame = pd.read_csv(csv_file_path, header=None)\n",
    "        self.root_dir = root_dir\n",
    "        self.dataset_frame_list = []\n",
    "        self.dataset = []\n",
    "        for i in range(CLASS_NUM):\n",
    "            if i == 1:\n",
    "                tmp_dataframe = data_frame[data_frame[LABEL_IDX]==i]\n",
    "                self.dataset_frame_list.append(tmp_dataframe[:end])\n",
    "            elif i == 2:\n",
    "                tmp_dataframe = data_frame[data_frame[LABEL_IDX]==i]\n",
    "                self.dataset_frame_list.append(tmp_dataframe[start:end])\n",
    "            elif i == 3:\n",
    "            elif i == 0:\n",
    "            else:\n",
    "                self.dataset_frame_list.append(data_frame[data_frame[LABEL_IDX]==i])\n",
    "            self.dataset.append( self.create_dataset(i) )\n",
    "\n",
    "    def create_dataset(self, label):\n",
    "        data_frame = self.get_dataframe(label)\n",
    "        data_list = []\n",
    "\n",
    "        for idx, row_data in data_frame.iterrows():\n",
    "            img_no = str(row_data[0])\n",
    "\n",
    "            png_img_name = row_data[1]\n",
    "\n",
    "            img_names = row_data[2:IMG_IDX+IMG_CHANNEL]\n",
    "            img_names = [ path for path in img_names ]\n",
    "\n",
    "            label = row_data[LABEL_IDX]\n",
    "            #label = np_utils.to_categorical(label, num_classes=CLASS_NUM)\n",
    "\n",
    "            image = self.load_image(img_names)\n",
    "            image = self.crop_center(image, IMG_SIZE, IMG_SIZE)\n",
    "            image = self.median_filter(image, 5)\n",
    "            #image = self.normalize2(image)\n",
    "            #image_feature = self.extract_feature(( normalized_image + 0.5 )*10)\n",
    "            #print(image_feature, label)\n",
    "\n",
    "            data_list.append( (label, image, img_no, png_img_name, img_names) )\n",
    "\n",
    "        return data_list\n",
    "    \n",
    "    \n",
    "    def normalize1(self, image):\n",
    "        flat_image = image.flatten()\n",
    "        mean = flat_image.mean()\n",
    "        std = flat_image.std()\n",
    "        image = np.where(image < mean - 3*std, mean - 3*std, image)\n",
    "        image = np.where(image > mean + 3*std, mean + 3*std, image)\n",
    "        image = (image + 3*std - mean)\n",
    "        \n",
    "        return image\n",
    "    \n",
    "    def normalize2(self, image):\n",
    "        image = image + 1.0\n",
    "        image = np.where(image < 0, 0, image)\n",
    "        image = np.where(image  > 5, 5, image)\n",
    "        return image\n",
    "    \n",
    "    def median_filter(self, image, ksize):\n",
    "        # 畳み込み演算をしない領域の幅\n",
    "        d = int((ksize - 1) / 2)\n",
    "        h, w = image.shape[0], image.shape[1]\n",
    "\n",
    "        # 出力画像用の配列（要素は入力画像と同じ）\n",
    "        dst = image.copy()\n",
    "\n",
    "        for y in range(d, h - d):\n",
    "            for x in range(d, w - d):\n",
    "                # 近傍にある画素値の中央値を出力画像の画素値に設定\n",
    "                dst[y][x] = np.median(image[y - d:y + d + 1, x - d:x + d + 1])\n",
    "\n",
    "        return dst\n",
    "\n",
    "    def special_median_filter(self, src, ksize):\n",
    "        # 畳み込み演算をしない領域の幅\n",
    "        d = int((ksize - 1) / 2)\n",
    "        h, w, c = src.shape[0], src.shape[1], src.shape[2]\n",
    "\n",
    "        # 出力画像用の配列（要素は入力画像と同じ）\n",
    "        dst = src.copy()\n",
    "        result = src.copy()\n",
    "\n",
    "        for i in range(c):\n",
    "            for y in range(d, h - d):\n",
    "                for x in range(d, w - d):\n",
    "                    # 近傍にある画素値の中央値を出力画像の画素値に設定\n",
    "                    dst[y][x][i] = np.median(src[y - d:y + d + 1, x - d:x + d + 1, i])\n",
    "\n",
    "        means = []\n",
    "        for i in range(c):\n",
    "            means.append(np.mean(src[:, :, i] - dst[:, :, i]))\n",
    "\n",
    "        for i in range(c):\n",
    "            for y in range(d, h - d):\n",
    "                for x in range(d, w - d):\n",
    "                    # 近傍にある画素値の中央値を出力画像の画素値に設定\n",
    "                    pixel = src[y, x, i]\n",
    "                    # print(pixel - dst[y, x, i])\n",
    "                    if pixel == 0 or pixel == 255:\n",
    "                        result[y, x, i] = dst[y, x, i]\n",
    "                    elif pixel - dst[y, x, i] > means[i]:\n",
    "                        result[y, x, i] = dst[y, x, i]\n",
    "        return result\n",
    "        \n",
    "    def crop_center(self, img,cropx, cropy):\n",
    "        y,x,z = img.shape\n",
    "        startx = x//2-(cropx//2)\n",
    "        starty = y//2-(cropy//2)\n",
    "        return img[starty:starty+cropy,startx:startx+cropx,:]\n",
    "\n",
    "    def get_dataframe(self, label):\n",
    "        return self.dataset_frame_list[label]\n",
    "\n",
    "    def get_dataset(self, label):\n",
    "        return self.dataset[label]\n",
    "\n",
    "    def zoom_img(self, img, original_size, pickup_size):\n",
    "        startpos = int(original_size / 2) - int(pickup_size / 2)\n",
    "        img = img[startpos:startpos+pickup_size, startpos:startpos+pickup_size]\n",
    "        return img\n",
    "\n",
    "    def load_image(self, img_paths):\n",
    "        image_path_list = [self.root_dir + img_path for img_path in img_paths]\n",
    "        image_list = []\n",
    "        for filepath in image_path_list:\n",
    "            row_data = fits.getdata(filepath)\n",
    "            image_list.append(row_data)\n",
    "        image = np.array([img for img in image_list]).transpose(1,2,0)\n",
    "        return image\n",
    "\n",
    "\n",
    "\n",
    "#create dataset for cross validation\n",
    "print('data read start')\n",
    "\n",
    "dataset_no_normalize = DatasetLoader(DATASET, DATA_ROOT_DIR, 1, 5000)\n",
    "other_dataset_no_normalize = DatasetLoader(DATASET, DATA_ROOT_DIR, start=5001)\n",
    "print('finished')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('dropout_4c_fits_median5.pickle', mode='wb') as f3:\n",
    "    pickle.dump(dataset_no_normalize, f3)\n",
    "\n",
    "with open('dropout_4c_fits_other_median5.pickle', mode='wb') as f4:\n",
    "    pickle.dump(other_dataset_no_normalize, f4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalize start\n",
      "normalize finished\n"
     ]
    }
   ],
   "source": [
    "def normalize1(image):\n",
    "    flat_image = image.flatten()\n",
    "    mean = flat_image.mean()\n",
    "    std = flat_image.std()\n",
    "    image = np.where(image < mean - 2*std, mean - 2*std, image)\n",
    "    image = np.where(image > mean + 2*std, mean + 2*std, image)\n",
    "    image = (image - image.min())\n",
    "\n",
    "    return image\n",
    "\n",
    "def normalize2(image):\n",
    "    image = image + 1.0\n",
    "    image = np.where(image < 0, 0, image)\n",
    "    image = np.where(image  > 4, 4, image)\n",
    "    image = image\n",
    "    return image\n",
    "\n",
    "def normalize_all_data(dataset_obj):\n",
    "    for data_list in dataset_obj.dataset:\n",
    "        for idx in range(len(data_list)):\n",
    "            (label, image, img_no, png_img_name, img_names) = data_list[idx]\n",
    "            data_list[idx] =  (label, normalize2(image), img_no, png_img_name, img_names)\n",
    "\n",
    "def normalize_all_data2(dataset_obj):\n",
    "    \n",
    "    for idx in range(len(dataset_obj)):\n",
    "        (label, image, img_no, png_img_name, img_names) = dataset_obj[idx]\n",
    "        dataset_obj[idx] =  (label, DatasetLoader.normalize2(None, image), img_no, png_img_name, img_names)\n",
    "            \n",
    "print('normalize start')\n",
    "with open('dropout_4c_fits.pickle', mode='rb') as f1:\n",
    "    dataset_no_normalize = pickle.load(f1)\n",
    "    \n",
    "with open('dropout_4c_fits_other.pickle', mode='rb') as f2:\n",
    "    other_dataset_no_normalize = pickle.load(f2)\n",
    "\n",
    "dataset = dataset_no_normalize\n",
    "other_dataset = other_dataset_no_normalize\n",
    "normalize_all_data(dataset)\n",
    "true_dataset = dataset.get_dataset(1)\n",
    "false_dataset = dataset.get_dataset(0)\n",
    "\n",
    "normalize_all_data(other_dataset)\n",
    "other_true_dataset = other_dataset.get_dataset(1)\n",
    "other_true_test_img = list(map(lambda data: data[1], other_true_dataset))\n",
    "other_true_test_label = list(map(lambda data: data[0], other_true_dataset))\n",
    "other_true_test_catalog_ids_set = list(map(lambda data: data[2], other_true_dataset))\n",
    "other_true_test_png_img_set = list(map(lambda data: data[3], other_true_dataset))\n",
    "other_true_test_paths_set = list(map(lambda data: data[4], other_true_dataset))\n",
    "print('normalize finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n",
      "0\n",
      "true train 3999\n",
      "true test 8265\n",
      "false train 3990\n",
      "false test 53\n",
      "7265\n",
      "0.9796826160134647\n",
      "[[  26   27]\n",
      " [ 142 8123]]\n",
      "1\n",
      "true train 3999\n",
      "true test 8265\n",
      "false train 3990\n",
      "false test 53\n",
      "7265\n",
      "0.9810050492906949\n",
      "[[  20   33]\n",
      " [ 125 8140]]\n",
      "2\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-38bd157c1794>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0mtrue_test_paths_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrue_test_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mother_true_test_paths_set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m     \u001b[0mfalse_train_img_feature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mextract_feature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfalse_train_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m     \u001b[0mfalse_train_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfalse_train_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m     \u001b[0mfalse_train_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfalse_train_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-38bd157c1794>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0mtrue_test_paths_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrue_test_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mother_true_test_paths_set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m     \u001b[0mfalse_train_img_feature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mextract_feature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfalse_train_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m     \u001b[0mfalse_train_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfalse_train_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m     \u001b[0mfalse_train_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfalse_train_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-38bd157c1794>\u001b[0m in \u001b[0;36mextract_feature\u001b[0;34m(image)\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0mcropped_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mchannel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalc_pixel_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcropped_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m             \u001b[0mfeature_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m             \u001b[0mfeature_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import itertools\n",
    "IMG_CHANNEL = 4\n",
    "\n",
    "FEATURE_RANGE = [15, 30]\n",
    "PATTERNS = list(itertools.combinations([i for i in range(IMG_CHANNEL)], 2))\n",
    "\n",
    "def extract_feature(image):\n",
    "    feature_list = []\n",
    "    #image = median_filter(image, 6)\n",
    "    for size in FEATURE_RANGE:\n",
    "        for (channel1, channel2) in PATTERNS:\n",
    "            image1 = image[:,:,channel1]\n",
    "            image2 = image[:,:,channel2]\n",
    "            feature_list.append(calc_pixel_ratio(image1, image2, size))\n",
    "            feature_list.append(calc_pixel_ratio_exp(image1, image2, size))\n",
    "\n",
    "        for channel in range(IMG_CHANNEL):\n",
    "            cropped_image = image[:,:,channel]\n",
    "            mean, std = calc_pixel_mean(cropped_image, size)\n",
    "            feature_list.append(mean)\n",
    "            feature_list.append(std*std)\n",
    "            \n",
    "    return np.array( feature_list )\n",
    "\n",
    "def median_filter(image, ksize):\n",
    "    # 畳み込み演算をしない領域の幅\n",
    "    d = int((ksize - 1) / 2)\n",
    "    h, w = image.shape[0], image.shape[1]\n",
    "\n",
    "    # 出力画像用の配列（要素は入力画像と同じ）\n",
    "    dst = image.copy()\n",
    "\n",
    "    for y in range(d, h - d):\n",
    "        for x in range(d, w - d):\n",
    "            # 近傍にある画素値の中央値を出力画像の画素値に設定\n",
    "            dst[y][x] = np.median(image[y - d:y + d + 1, x - d:x + d + 1])\n",
    "    return dst\n",
    "\n",
    "def special_median_filter(src, ksize):\n",
    "    # 畳み込み演算をしない領域の幅\n",
    "    d = int((ksize - 1) / 2)\n",
    "    h, w, c = src.shape[0], src.shape[1], src.shape[2]\n",
    "\n",
    "    # 出力画像用の配列（要素は入力画像と同じ）\n",
    "    dst = src.copy()\n",
    "    result = src.copy()\n",
    "\n",
    "    for i in range(c):\n",
    "        for y in range(d, h - d):\n",
    "            for x in range(d, w - d):\n",
    "                # 近傍にある画素値の中央値を出力画像の画素値に設定\n",
    "                dst[y][x][i] = np.median(src[y - d:y + d + 1, x - d:x + d + 1, i])\n",
    "\n",
    "    means = []\n",
    "    for i in range(c):\n",
    "        means.append(np.mean(src[:, :, i] - dst[:, :, i]))\n",
    "\n",
    "    for i in range(c):\n",
    "        for y in range(d, h - d):\n",
    "            for x in range(d, w - d):\n",
    "                # 近傍にある画素値の中央値を出力画像の画素値に設定\n",
    "                pixel = src[y, x, i]\n",
    "                # print(pixel - dst[y, x, i])\n",
    "                if pixel == 0 or pixel == 255:\n",
    "                    result[y, x, i] = dst[y, x, i]\n",
    "                elif pixel - dst[y, x, i] > means[i]:\n",
    "                    result[y, x, i] = dst[y, x, i]\n",
    "    return result\n",
    "\n",
    "def calc_pixel_mean(image, size):\n",
    "    cropped_image = crop_center2D(image, size, size)\n",
    "    return cropped_image.mean(), cropped_image.std()\n",
    "\n",
    "def calc_pixel_ratio(image1, image2, size):\n",
    "    cropped_image1 = crop_center2D(image1, size, size)\n",
    "    cropped_image2 = crop_center2D(image2, size, size)\n",
    "\n",
    "    return cropped_image1.sum()/cropped_image2.sum()\n",
    "\n",
    "def calc_pixel_ratio_exp(image1, image2, size):\n",
    "    cropped_image1 = crop_center2D(image1, size, size)\n",
    "    cropped_image2 = crop_center2D(image2, size, size)\n",
    "\n",
    "    return np.exp(cropped_image1).sum()/np.exp(cropped_image2).sum()\n",
    "\n",
    "def crop_center2D(img,cropx, cropy):\n",
    "    y,x = img.shape\n",
    "    startx = x//2-(cropx//2)\n",
    "    starty = y//2-(cropy//2)\n",
    "    return img[starty:starty+cropy,startx:startx+cropx]\n",
    "\n",
    "def write_result(zipped_result, output_path):\n",
    "    with open(output_path, 'w') as f:\n",
    "        writer = csv.writer(f)\n",
    "        for result in zipped_result:\n",
    "            cat_id = result[0]\n",
    "            img_paths = result[2]\n",
    "            combined_img_path = result[1]\n",
    "            label = result[3]\n",
    "            float_formatter = lambda x: \"%.4f\" % x\n",
    "            pred = result[4]\n",
    "            # row should be [cat_id, img1, img2, img3, combined_img, correct_label, [probabilties], answer]\n",
    "            row = [cat_id, img_paths, combined_img_path, label, pred]\n",
    "            writer.writerow(row)\n",
    "\n",
    "print('start')\n",
    "kfold = KFold(n_splits=5, shuffle=True)\n",
    "\n",
    "true_dataset_fold = kfold.split(true_dataset)\n",
    "false_dataset_fold = kfold.split(false_dataset)\n",
    "\n",
    "accuracies = []\n",
    "for fold_idx, ( (true_train_idx, true_test_idx), (false_train_idx, false_test_idx) ) in\\\n",
    "        enumerate( zip(true_dataset_fold, false_dataset_fold) ):\n",
    "\n",
    "    print(fold_idx)\n",
    "    true_train_data = [ true_dataset[idx] for idx in true_train_idx]\n",
    "    true_test_data = [ true_dataset[idx] for idx in true_test_idx ]\n",
    "    false_train_data = [ false_dataset[idx] for idx in false_train_idx ]\n",
    "    false_test_data = [ false_dataset[idx] for idx in false_test_idx ]\n",
    "\n",
    "    #data augumentation\n",
    "    datagen = ImageDataGenerator(\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=True)\n",
    "\n",
    "    tmp_false_train_data = false_train_data\n",
    "    false_train_data = []\n",
    "    for idx, data in enumerate( tmp_false_train_data ):\n",
    "        label = data[0]\n",
    "        img = data[1]\n",
    "        img_no = data[2]\n",
    "        img_name = data[3]\n",
    "        img_names = data[4]\n",
    "        expanded_image = np.expand_dims(img, axis=0)\n",
    "        generator = datagen.flow(expanded_image, batch_size=1, save_prefix='img', save_format='png')\n",
    "        for ite in range(19):\n",
    "            batch = generator.next()\n",
    "            false_train_data.append( (label, batch[0], img_no, img_name, img_names) )\n",
    "\n",
    "    true_train_img_feature = list(map(lambda data: extract_feature(data[1]), true_train_data))\n",
    "    true_train_img = list(map(lambda data: data[1], true_train_data))\n",
    "    true_train_label = list(map(lambda data: data[0], true_train_data))\n",
    "    \n",
    "    true_test_img_feature = list(map(lambda data: extract_feature(data[1]), true_test_data)) + [extract_feature(data) for data in other_true_test_img]\n",
    "    true_test_img = list(map(lambda data: data[1], true_test_data)) + other_true_test_img\n",
    "    true_test_label = list(map(lambda data: data[0], true_test_data)) + other_true_test_label\n",
    "    true_test_catalog_ids_set = list(map(lambda data: data[2], true_test_data)) + other_true_test_catalog_ids_set\n",
    "    true_test_png_img_set = list(map(lambda data: data[3], true_test_data)) + other_true_test_png_img_set\n",
    "    true_test_paths_set = list(map(lambda data: data[4], true_test_data)) + other_true_test_paths_set\n",
    "    \n",
    "    false_train_img_feature = list(map(lambda data: extract_feature(data[1]), false_train_data))\n",
    "    false_train_img = list(map(lambda data: data[1], false_train_data))\n",
    "    false_train_label = list(map(lambda data: data[0], false_train_data))\n",
    "    \n",
    "    false_test_img_feature = list(map(lambda data: extract_feature(data[1]), false_test_data))\n",
    "    false_test_img = list(map(lambda data: data[1], false_test_data))\n",
    "    false_test_label = list(map(lambda data: data[0], false_test_data))\n",
    "    false_test_catalog_ids_set = list(map(lambda data: data[2], false_test_data))\n",
    "    false_test_png_img_set = list(map(lambda data: data[3], false_test_data))\n",
    "    false_test_paths_set = list(map(lambda data: data[4], false_test_data))\n",
    "    \n",
    "    train_img_feature = true_train_img_feature + false_train_img_feature\n",
    "    train_label = true_train_label + false_train_label\n",
    "    \n",
    "    test_img_feature = true_test_img_feature + false_test_img_feature\n",
    "    test_label = true_test_label + false_test_label\n",
    "    test_catalog_id_set = true_test_catalog_ids_set + false_test_catalog_ids_set\n",
    "    test_png_img_set = true_test_png_img_set + false_test_png_img_set\n",
    "    test_path_set = true_test_paths_set + false_test_paths_set\n",
    "    \n",
    "    print('true train', len(true_train_img))\n",
    "    print('true test', len(true_test_img))\n",
    "    print('false train', len(false_train_img))\n",
    "    print('false test', len(false_test_img))\n",
    "\n",
    "    #SVM classification\n",
    "    model = SVC()\n",
    "    model.fit(train_img_feature, train_label)\n",
    "\n",
    "    pred_result = model.predict(test_img_feature)\n",
    "    write_result(zip(test_catalog_id_set, test_png_img_set, test_path_set, test_label, pred_result), 'res{}.csv'.format(fold_idx))\n",
    "    print(len(other_true_test_img))\n",
    "    print(metrics.accuracy_score(test_label, pred_result))\n",
    "    print(metrics.confusion_matrix(test_label, pred_result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "normalize 2 , 4ch\n",
    "start\n",
    "0\n",
    "true train 3999\n",
    "true test 8265\n",
    "false train 3990\n",
    "false test 53\n",
    "0.982327482567925\n",
    "[[  40   13]\n",
    " [ 134 8131]]\n",
    "1\n",
    "true train 3999\n",
    "true test 8265\n",
    "false train 3990\n",
    "false test 53\n",
    "0.9843712430872806\n",
    "[[  43   10]\n",
    " [ 120 8145]]\n",
    "2\n",
    "true train 3999\n",
    "true test 8265\n",
    "false train 3990\n",
    "false test 53\n",
    "0.9854532339504689\n",
    "[[  22   31]\n",
    " [  90 8175]]\n",
    "3\n",
    "true train 3999\n",
    "true test 8265\n",
    "false train 4009\n",
    "false test 52\n",
    "0.970181555849465\n",
    "[[   3   49]\n",
    " [ 199 8066]]\n",
    "4\n",
    "true train 4000\n",
    "true test 8264\n",
    "false train 4009\n",
    "false test 52\n",
    "0.971981721981722\n",
    "[[   1   51]\n",
    " [ 182 8082]]\n",
    "\n",
    "normalize1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
